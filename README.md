Terradatum JDBC for ORDBMS
==========================

Why another data access abstraction?

This project was born of the question: how can I run an application targeting both Postgres Plus Advanced Server (PPAS) and
Oracle?

Given an object `TABLE` type composed of the following:
```sql
CREATE OR REPLACE TYPE JDBC_TEST.CHILD_OBJ AS OBJECT
(
  CHILD_ID   NUMBER,
  CHILD_NAME VARCHAR(20)
);

CREATE OR REPLACE TYPE JDBC_TEST.CHILD_TBL AS TABLE OF JDBC_TEST.CHILD_OBJ;

CREATE OR REPLACE TYPE JDBC_TEST.SUB_PARENT_OBJ AS OBJECT
(
  SUB_PARENT_ID NUMBER,
  PARENT_TYPE   VARCHAR(20)
);

CREATE OR REPLACE TYPE JDBC_TEST.PARENT_OBJ AS OBJECT
(
  PARENT_ID      NUMBER,
  PARENT_NAME    VARCHAR(20),
  SUB_PARENT     JDBC_TEST.SUB_PARENT_OBJ,
  SOME_DATE      DATE,
  SOME_TIMESTAMP TIMESTAMP,
  IMAGE          BLOB,
  CHILDREN       JDBC_TEST.CHILD_TBL
);

CREATE OR REPLACE TYPE JDBC_TEST.PARENT_TBL AS TABLE OF JDBC_TEST.PARENT_OBJ;
```

**Oracle:**
```java
OracleCallableStatement cs =
  connection.prepareCall("{? = call parent_child_pkg.get_parents_by_type(?)}");
cs.registerOutParameter(1, ChildTbl._SQL_TYPECODE, ChildTbl._SQL_NAME);
cs.setString(2, "ape");

cs.execute();

ParentTbl parentTbl = (ParentTbl)cs.getORAData(1, ParentTbl.getORADataFactory();
ParentObj ParentObj = parentTbl.get(1);
SubParentObj subParentObj = parentObj.getSubParent();
String parentType = subParentObj.getParentType();
```

**EDB:**
```java
CallableStatement cs =
  connection.prepareCall("{? = call parent_child_pkg.get_parents_by_type(?)}");
cs.registerOutParameter(1, Types.ARRAY);
cs.setBigDecimal(2, BigDecimal.valueOf(1));

cs.execute();

Array parentTblArray = cs.getArray(1)
Struct[] parentTbl = (Struct[])parentTblArray.getArray();
Struct parentObj = parentTbl[0];
Struct subParentObj = (Struct)parentObj.getAttributes[2];
String parentType = (String)subParentObj.getAttributes[1];
```

**Terradatum JDBC for Oracle and EDB:**
```java
DbCallableStatementAdapter cs =
  connectionAdapter.prepareCallAdapter("{? = call some_pkg.get_table_type_by_id(?)}");
cs.registerArrayOutParameter(1, MyTbl.SQL_TYPE_NAME);
cs.setNumeric(2, 1);

cs.execute();

MyTbl myTbl = cs.getArray(1, MyTbl.class);
MyObj myObj = myTbl.get(1);
MyOtherObj myOtherObj = myObj.getBaz();
String bar = myOtherObj.getBar();
```

PPAS has remarkable feature parity with Oracle at the database level, with support for PG/SQL partitioning language (as opposed to
the PostgreSQL rules-based partitioning), packages and collection Object-Relational (ORDBMS) types. What options do you have if,
for better of worse, you make heavy use of in-database ORDBMS types (`OBJECT` and `TABLE` types)?

The EnterpriseDB (EDB) JDBC drivers do not offer the same level of support as OJDBC, making it a challenge when trying to write
code that will work with both PPAS and Oracle ORDBMS constructs.

The tools usually used to abstract away the differences between PPAS and Oracle all require non-trivial effort - in every case
needing almost the same amount of effort as that required to add a completely new database to their list of supported RDBMS'.

The Landscape
-------------

### Oracle ORDBMS and the OJDBC extensions
When working with Oracle ORDBMS types, the OJDBC extensions offer an out-of-the-box code generator, JPublisher, which can
basically produce two types of output: Oracle-proprietary and JDBC.

1. The Oracle output creates both `OBJECT` and `TABLE` representations in Java, where the `oracle.jdbc.STRUCT` types provide
strongly-typed POJOs with accessors and mutators, and the `oracle.jdbc.ARRAY` types offer strongly-typed collection semantics.
Both are implementations of the `ORAData` and `ORADataFactory` interfaces and offer all the plumbing necessary to work closely
with the OJDBC extensions - like sending and receiving object and collection types as input and output parameters for functions
and procedures.
2. The JDBC output creates Java representations based on the JDBC `SQLData` interface and the `SQLInput` and `SQLOutput` streams.
There are no collection types, per-se, though the support for `SQLMap`'s allows the developer to get very close to the same
functionality found in the Oracle-specific JDBC extensions. The `SQLData` interface implementations generated by JPublisher (or
created by hand) give the user strongly-typed POJOs too - and the plumbing necessary to deal with collection types is minimal.

If you are working with code based on option #1 above, your codebase will be tightly coupled with the "Oracle way" of
accessing ORDBMS types, making heavy use of the `ORAData` and `ORADataFactor` interfaces and calling directly into and out of the
OJDBC API. Any attempt to leverage JPA needs to have a low barrier to entry, as you will have to refactor your data access
layer to use JPA in the first place. Having to build a large contribution to a JPA provider just to get to the point where you
could _start_ integrating JPA into your middle-tier will likely be cost prohibitive.

Option #2 isn't going to work for you with the EDB JDBC drivers either - while the `SQLData` interface is a part of the JDBC
version 4 specification, neither the PGJDBC nor EDB JDBC drivers support it. You *MUST* use what is known as the "weak" reference
APIs - namely `java.sql.Struct` (e.g. [`Connection#createStruct`][1]) and `java.sql.Array` (e.g. [`Connection#createArrayOf`][2]).

### JPA + Provider
[EclipseLink][3] has support for Oracle-specific constructs like [Struct][4], [PLSQL Table types][5] and [Named PLSQL
Functions][6] to name just a few. However, these extensions _will not work_ with the EDB JDBC drivers because they rely
exclusively on the Oracle JDBC driver extensions.

Both EclipseLink and [NHibernate][7] are extensible enough that it is possible to add a "[dialect][8]" for PPAS that would allow
these providers to translate their internals to the "PPAS way". However, JPA itself doesn't do well with ORDBMS types - hence the
need for the EclipseLink extensions. After thoroughly reviewing the EclipseLink codebase it was clear that attempting to leverage
the work already done to support ORDBMS objects in Oracle _could_ be done for PPAS in EclipseLink, however that work would take
significant effort. With NHibernate it would be even more work.

JPA has the concept of a "Native Query" which could be used to call into either PPAS or Oracle. The question still remains how
the data would be hydrated into and out of a model.

In the end, the problem comes down to the fact that PPAS just doesn't have the visibility as other RDBMS's, so all the effort that
has been put into making JPA work with PostgreSQL, for instance, is useful only in that you can use that same functionality in
PPAS. Any additional functionality you may be looking to access in PPAS, like packages or collection types, isn't supported.

### Spring JdbcTemplate and jOOQ
While [Spring's JdbcTemplate][9] and [jOOQ][10] are a better fit than JPA because their API's run "closer to the metal" of the
JDBC API, neither has an implementation that supports those features offered by PPAS that are divergent from PostgreSQL. Again,
much work would need to be done to add functionality to both in order to support the needs of an application that requires the
ORDBMS abilities of PPAS.

The Solution
------------

### Requirements
1. Strongly typed POJOs.
2. Strongly typed collections.
3. Ability to work with functions and procedures such that objects can be used as both IN and OUT parameters.
4. Single API for both PPAS and Oracle.
5. Closely aligned API which mimics the JDBC API as closely as possible.

### Implementation

#### API

The API uses the adapter and decorator patterns to provide a fully-functional JDBC API, delegating client calls into the
underlying connection. When working with `OBJECT` or `TABLE` Java representations, the API expects those representations to
implement or extend a custom interface or class:
* [`DbStruct`][11] - an extension to the `java.sql.Struct` JDBC interface that supports hydrating and dehydrating objects. The
challenge here is that the JDBC `Struct` type is essentially a read-only interface, where the caller is expected to use an
instance of the JDBC `java.sql.Connection` to `createStruct` before then passing that `Struct` in as a parameter, or via one of
the calls that retrieves the data from the database and hydrates the `Struct` before the caller accesses it. With similar
incantations required for working with `java.sql.Array` types.
* [`JdbcArrayList`][12] & [`StructArrayList`][13] - wraps and understands how to inspect and hydrate `Array` and `Struct` types.
Decorates the [Guava][14] [`ForwardingList<T>`][15].
* [`DbConnectionAdapter`][16], [`DbStatementAdapter`][17], [`DbPreparedStatementAdapter`][18] and [`DbCallableStatementAdapter`][19]
interfaces and their abstract EDB and Oracle implementations. The decorations on these adapters adjust their behavior to suite the
underlying connection, e.g. use `createArrayOf` for EDB and `createARRAY` for Oracle.

**Maven** _(this is pending - haven't yet pushed an artifact to the Central repository)_
```xml
<dependency>
  <groupId>com.terradatum</groupId>
  <artifactId>terradatum-jdbc</artifactId>
  <version>1.0-SNAPSHOT</version> <!-- once published to Central, this will change -->
</dependency>
```

#### Code Generation

While you could hand-craft your implementation of the `DbStruct` and `StructArrayList` models, it's not required as there is a
codegen and maven plugin that harnesses that generator.

You can also pull the [StringTemplate][20] ([templates][21]) files from this repository and use them as a starting point for
further customizing your model implementation. The plugin will look for these files in `src/main/resources/templates` unless
your configuration tells it otherwise. If you don't supply your own StringTemplate group files, the code generator will use
the ones supplied with the library.

The code generator only pulls model data from PPAS in the assumption that it is the single source of truth - it could further be
extended to support Oracle, but that wasn't on the roadmap.

Currently the `terradatum-jdbc-codegen` artifact is not a runnable JAR - it has outside dependencies and no MANIFEST.MF file.
Creating a fat JAR and tooling it up so that it can run on the command line is not currently on the roadmap either.

However, there is a Maven plugin.

**Maven:** _(this is pending - haven't yet pushed an artifact to the Central repository)_
```xml
<build>
  <plugins>
    <plugin>
      <groupId>com.terradatum</groupId>
      <artifactId>terradatum-jdbc-codegen-plugin</artifactId>
      <version>1.0-SNAPSHOT</version>
      <configuration>
        <!--skip>true</skip-->
        <url>${edb.connection-url}</url>
        <username>${edb.username}</username>
        <password>${edb.password}</password>
        <package-name>com.terradatum</package-name>
        <!-- Schemas to search to create model from - name appended to package name above -->
        <schemas>
          <schema>monkeys</schema>
          <schema>humans</schema>
        </schemas>
        <!-- Regex pattern, whitespace ignored and comments allowed. Use '?i:' for case-insensitive regex -->
        <type-includes>(?i: jdbc_test\.my_obj| monkeys\.my_other_obj| monkeys\.my_tbl)</type-includes>
        <type-excludes>(?i: humans\.some_obj| humans\.some_other_obj)</type-excludes>
      </configuration>
      <executions>
        <execution>
          <id>generate-model</id>
          <goals>
            <goal>generate</goal>
          </goals>
        </execution>
      </executions>
      <dependencies>
        <!-- If the EDB JDBC driver is marked as 'provided' scope, you may need the following stanza -->
        <dependency>
          <groupId>com.edb</groupId>
          <artifactId>edb-jdbc17</artifactId>
          <version>${edb-jdbc.version}</version>
          <scope>compile</scope>
        </dependency>
      </dependencies>
    </plugin>
  </plugins>
</build>
```
To get more information about the available configuration you can run:
```bash
mvn help:describe -Dplugin=com.terradatum:terradatum-jdbc-codegen-plugin
```
The code generator ships with the three StringTemplate group files necessary to create the object model.

If you want to customize those templates, by default the plugin looks in `src/main/resources/templates` for three template group
files:

1. types.stg - maps database types to Java types
2. ojb.stg - the `OBJECT` to `DbStruct` template
3. tbl.stg - tho `TABLE` to `JdbcArrayList` or `StructArrayList` template
The location of the template group files can be changed using the Maven configuration.

By default the output is placed in `target/generated-sources/jdbc-codegen`.

**Example `DbStruct`:**
```java
package com.terradatum.jdbc.db.objects.jdbcTest;

import com.terradatum.jdbc.converters.ConverterUtil;
import com.terradatum.jdbc.DbStruct;
import com.google.common.base.MoreObjects;

import java.lang.reflect.InvocationTargetException;
import java.sql.SQLException;
import java.sql.Struct;
import java.util.Map;
import java.util.Objects;

/**
 * DO NOT MODIFY!!! This class was generated by the Terradatum JDBC Code Generator and will be overwritten if regenerated
 * @date 2016-03-28T19:45:12.424
 */
public class ParentObj implements DbStruct {
  public static final String SQL_TYPE_NAME = "jdbc_test.parent_obj";

  private java.math.BigDecimal parentId;
  private String parentName;
  private com.terradatum.jdbc.db.objects.jdbcTest.SubParentObj subParent;
  private java.sql.Timestamp someDate;
  private java.sql.Timestamp someTimestamp;
  private byte[] image;
  private com.terradatum.jdbc.db.objects.jdbcTest.ChildTbl children;

  /**
   * Required default constructor.
   */
  public ParentObj() {
  }

  /**
   * All-elements, type-safe constructor
   */
  public ParentObj(java.math.BigDecimal parentId, String parentName, com.terradatum.jdbc.db.objects.jdbcTest.SubParentObj subParent, java.sql.Timestamp someDate, java.sql.Timestamp someTimestamp, byte[] image, com.terradatum.jdbc.db.objects.jdbcTest.ChildTbl children) {
    this.parentId = parentId;
    this.parentName = parentName;
    this.subParent = subParent;
    this.someDate = someDate;
    this.someTimestamp = someTimestamp;
    this.image = image;
    this.children = children;

  }

  /**
   * Set the {@link Struct}, which is then parsed and hydrated into the properties of the {@link DbStruct}.
   *
   * There are numerous casts and other shenanigans occurring here, so this method can throw numerous exceptions.
   * This is a better solution than a method that hides all exceptions and prevents the call site from responding
   * accordingly.
   * @param struct the {@link java.sql.Struct} which is used as the model for this {@link DbStruct} object
   * @throws SQLException
   * @throws NoSuchMethodException
   * @throws NoSuchFieldException
   * @throws IllegalAccessException
   * @throws InvocationTargetException
   */
  @SuppressWarnings("unused")
  public void setStruct(Struct struct) throws SQLException, NoSuchMethodException, NoSuchFieldException,
            IllegalAccessException, InvocationTargetException {
    if (struct != null) {
      setAttributes(struct.getAttributes());
    }
  }

  @Override
  public String getSQLTypeName() throws SQLException {
    return SQL_TYPE_NAME;
  }

  @Override
  public Object[] getAttributes() throws SQLException {
    return new Object[]{parentId, parentName, subParent, someDate, someTimestamp, image, children};
  }

  @Override
  public Object[] getAttributes(Map<String, Class<?>> map) throws SQLException {
    return getAttributes();
  }

  @Override
  public void setAttributes(Object[] attributes) throws SQLException, InvocationTargetException,
            NoSuchMethodException, IllegalAccessException, NoSuchFieldException {
    parentId = ConverterUtil.convert(attributes[0], java.math.BigDecimal.class);
    parentName = ConverterUtil.convert(attributes[1], String.class);
    subParent = new com.terradatum.jdbc.db.objects.jdbcTest.SubParentObj();
    subParent.setStruct((Struct) attributes[2]);
    someDate = ConverterUtil.convert(attributes[3], java.sql.Timestamp.class);
    someTimestamp = ConverterUtil.convert(attributes[4], java.sql.Timestamp.class);
    image = ConverterUtil.convert(attributes[5], byte[].class);
    children = new com.terradatum.jdbc.db.objects.jdbcTest.ChildTbl();
    children.setArray(attributes[6]);
  }

  public java.math.BigDecimal getParentId() {
    return parentId;
  }

  public void setParentId(java.math.BigDecimal parentId) {
    this.parentId = parentId;
  }

  public String getParentName() {
    return parentName;
  }

  public void setParentName(String parentName) {
    this.parentName = parentName;
  }

  public com.terradatum.jdbc.db.objects.jdbcTest.SubParentObj getSubParent() {
    return subParent;
  }

  public void setSubParent(com.terradatum.jdbc.db.objects.jdbcTest.SubParentObj subParent) {
    this.subParent = subParent;
  }

  public java.sql.Timestamp getSomeDate() {
    return someDate;
  }

  public void setSomeDate(java.sql.Timestamp someDate) {
    this.someDate = someDate;
  }

  public java.sql.Timestamp getSomeTimestamp() {
    return someTimestamp;
  }

  public void setSomeTimestamp(java.sql.Timestamp someTimestamp) {
    this.someTimestamp = someTimestamp;
  }

  public byte[] getImage() {
    return image;
  }

  public void setImage(byte[] image) {
    this.image = image;
  }

  public com.terradatum.jdbc.db.objects.jdbcTest.ChildTbl getChildren() {
    return children;
  }

  public void setChildren(com.terradatum.jdbc.db.objects.jdbcTest.ChildTbl children) {
    this.children = children;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }

    ParentObj that = (ParentObj) o;
    return
      Objects.equals(getParentId(), that.getParentId()) &&
      Objects.equals(getParentName(), that.getParentName()) &&
      Objects.equals(getSubParent(), that.getSubParent()) &&
      Objects.equals(getSomeDate(), that.getSomeDate()) &&
      Objects.equals(getSomeTimestamp(), that.getSomeTimestamp()) &&
      Objects.equals(getImage(), that.getImage()) &&
      Objects.equals(getChildren(), that.getChildren());
  }

  @Override
  public int hashCode() {
    return Objects.hash(
        getParentId(),
        getParentName(),
        getSubParent(),
        getSomeDate(),
        getSomeTimestamp(),
        getImage(),
        getChildren());
  }

  @Override
  public String toString() {
    return MoreObjects.toStringHelper(this)
        .add("parentId", getParentId())
        .add("parentName", getParentName())
        .add("subParent", getSubParent())
        .add("someDate", getSomeDate())
        .add("someTimestamp", getSomeTimestamp())
        .add("image", getImage())
        .add("children", getChildren()).toString();
  }
}
```
**Example `StructArrayList<E>`:**
```java
package com.terradatum.jdbc.db.objects.jdbcTest;

import com.terradatum.jdbc.StructArrayList;

import java.lang.reflect.InvocationTargetException;
import java.sql.Array;
import java.sql.SQLException;
import java.util.ArrayList;

import static java.sql.Types.*;

/**
 * DO NOT MODIFY!!! This class was generated by the Terradatum JDBC Code Generator and will be overwritten if regenerated
 * @date 2016-03-28T19:46:25.442
 */
public class ParentTbl extends StructArrayList<com.terradatum.jdbc.db.objects.jdbcTest.ParentObj> {
  public static final String SQL_TYPE_NAME = "jdbc_test.parent_tbl";
  public static final char EDB_ARRAY_DELIMITER = ',';
  private final ArrayList<com.terradatum.jdbc.db.objects.jdbcTest.ParentObj> delegate = new ArrayList<>();

  /**
   * Required default constructor.
   */
  @SuppressWarnings("unused")
  public ParentTbl() {}

  @Override
  protected ArrayList<com.terradatum.jdbc.db.objects.jdbcTest.ParentObj> delegate() {
    return delegate;
  }

  @Override
  public String getSQLTypeName() {
    return SQL_TYPE_NAME;
  }

  @Override
  public String getBaseTypeName() {
    return com.terradatum.jdbc.db.objects.jdbcTest.ParentObj.SQL_TYPE_NAME;
  }

  @Override
  public int getBaseType() {
    return STRUCT;
  }

  @Override
  public char getEdbArrayDelimiter() {
    return EDB_ARRAY_DELIMITER;
  }

  @Override
  public ParentTbl setArray(Array array) throws SQLException, InvocationTargetException,
      NoSuchMethodException, IllegalAccessException, NoSuchFieldException {
    super.setArray(array);
    return this;
  }

  @Override
  public ParentTbl setElements(com.terradatum.jdbc.db.objects.jdbcTest.ParentObj[] elements) throws SQLException {
    super.setElements(elements);
    return this;
  }
}
```

### Compiling and Testing

You should be able to clone this repository and immediately compile it - as long as you've got access to a Nexus or other Maven
repository that has the Oracle and EDB drivers installed. Because of licensing, you will never find them in the public repos.

As well, the `terradatum-jdbc-parent` `pom.xml` file refers to an Organizational `pom.xml` - you won't have access to that, but
the project should be relatively self-sufficient and should have no requirements on that root pom.

#### Testing
In order for the tests to run, you need access to both Oracle and EDB PPAS. Each test is built to run twice, once against each RDBMS.

Please see the [readme][22] in the sql scripts directory for a brief explanation on how to create a `jdbc_test` database.
*NOTE:* You will need to run `mvn -pl terradatum-jdbc process-test-resources` and then use the filtered SQL scripts located in the
`target/generated-sql-scripts` directory. Again - follow the instructions and you should be good-to-go.

Good Luck!!!!

- G. Richard Bellamy and the Terradatum Team.

[1]: https://docs.oracle.com/javase/7/docs/api/java/sql/Connection.html#createStruct(java.lang.String,%20java.lang.Object[])
[2]: https://docs.oracle.com/javase/7/docs/api/java/sql/Connection.html#createArrayOf(java.lang.String,%20java.lang.Object[])
[3]: http://www.eclipse.org/eclipselink/documentation/
[4]: http://www.eclipse.org/eclipselink/documentation/2.6/jpa/extensions/annotations_ref.htm#CBBDCAHG
[5]: http://www.eclipse.org/eclipselink/documentation/2.6/jpa/extensions/annotations_ref.htm#CACJBHHF
[6]: http://www.eclipse.org/eclipselink/documentation/2.6/jpa/extensions/annotations_ref.htm#BGBDHGJE
[7]: http://nhibernate.info/doc/index.html
[8]: https://github.com/nhibernate/nhibernate-core/tree/master/src/NHibernate/Dialect
[9]: http://docs.spring.io/spring/docs/current/spring-framework-reference/html/jdbc.html
[10]: http://jooq.org
[11]: jdbc/src/main/java/com/terradatum/jdbc/DbStruct.java
[12]: jdbc/src/main/java/com/terradatum/jdbc/JdbcArrayList.java
[13]: jdbc/src/main/java/com/terradatum/jdbc/StructArrayList.java
[14]: https://github.com/google/guava
[15]: https://github.com/google/guava/wiki/CollectionHelpersExplained#forwarding-decorators
[16]: src/main/java/com/terradatum/jdbc/DbConnectionAdapter.java
[17]: src/main/java/com/terradatum/jdbc/DbStatementAdapter.java
[18]: src/main/java/com/terradatum/jdbc/DbPreparedStatementAdapter.java
[19]: src/main/java/com/terradatum/jdbc/DbCallableStatementAdapter.java
[20]: http://www.stringtemplate.org
[21]: codegen/codegen/src/main/resources/templates
[22]: jdbc/src/test/sql/READM.MD